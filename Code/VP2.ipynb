{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3015b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/cbr/VP2/VP2_SoilMapping/CodeOutput/output_file_channelFusion_3.tif\n",
      "bands 12 rows 5808 columns 6668\n",
      "(5808, 6668, 12)\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr, ogr\n",
    "from skimage import exposure\n",
    "from skimage.segmentation import quickshift, slic\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import os\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "\n",
    "#naip_fn = 'C:/Users/st1154414/Desktop/VP2/Data/Sursee_2020/2020-10-22_adi_Wetzwil-Mspec/img/MSP_00251_00005.tif'#\n",
    "#naip_fn = \"C:/Users/st1154414/Desktop/VP2/Data/Sursee_2020/2020-10-22_adi_beromuenster-nir/img/IMG_5971.JPG\"\n",
    "#naip_fn = \"C:/Users/st1154414/Desktop/VP2/Data/Sursee_2020/2020-10-22_adi_Wetzwil-RGB/img/DSC01500.JPG\"\n",
    "#naip_fn = \"C:/Users/st1154414/Desktop/VP2/Processed/Orthophoto_Berom_rgb.tif\"\n",
    "#naip_fn = \"C:/Users/st1154414/Desktop/VP2/Processed/merged2.tif\"\n",
    "#naip_fn = \"D:/cbr/VP2/CodeOutput/output_file_mspec.tif\"\n",
    "naip_fn = \"D:/cbr/VP2/VP2_SoilMapping/CodeOutput/output_file_channelFusion_4.tif\"\n",
    "\n",
    "print(naip_fn)\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "naip_ds = gdal.Open(naip_fn)\n",
    "\n",
    "nbands = naip_ds.RasterCount\n",
    "band_data = []\n",
    "\n",
    "print('bands', naip_ds.RasterCount, 'rows', naip_ds.RasterYSize, 'columns', naip_ds.RasterXSize)\n",
    "for i in range(1, nbands+1):\n",
    "        band = naip_ds.GetRasterBand(i).ReadAsArray()\n",
    "        band_data.append(band)\n",
    "\n",
    "band_data = np.dstack(band_data)\n",
    "print(band_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39e4696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments complete 92.22416639328003\n"
     ]
    }
   ],
   "source": [
    "# scale image values from 0.0 - 1.0\n",
    "#band_data[np.isnan(band_data)] = 0\n",
    "band_data[np.isnan(band_data)] = -9999.0\n",
    "img = exposure.rescale_intensity(band_data, in_range= (0.0, 225))\n",
    "\n",
    "# do segmentation multiple options with quickshift and slic\n",
    "seg_start = time.time()\n",
    "# segments = quickshift(img, convert2lab=False)\n",
    "#segments = quickshift(img, ratio=0.8, convert2lab=False)\n",
    "# segments = quickshift(img, ratio=0.99, max_dist=5, convert2lab=False)\n",
    "#segments = slic(img, n_segments=100000, compactness=0.1, start_label = 1)\n",
    "#segments = slic(img, n_segments=500000, compactness=0.01, start_label = 1)\n",
    "segments = slic(img, n_segments=1000, compactness=3, start_label = 1)\n",
    "print('segments complete', time.time() - seg_start)\n",
    "\n",
    "def segment_features(segment_pixels):\n",
    "    features = []\n",
    "    npixels, nbands = segment_pixels.shape\n",
    "    for b in range(nbands):\n",
    "        stats = scipy.stats.describe(segment_pixels[:, b])\n",
    "        band_stats = list(stats.minmax) + list(stats)[2:]\n",
    "        if npixels == 1:\n",
    "            band_stats[3] = 0.0\n",
    "        features += band_stats\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3e17a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = np.unique(segments)\n",
    "objects = []\n",
    "object_ids = []\n",
    "for id in segment_ids:\n",
    "    segment_pixels = img[segments == id]\n",
    "    object_features = segment_features(segment_pixels)\n",
    "    objects.append(object_features)\n",
    "    object_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6a01fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0 max 0 mean 0.0\n",
      "class values []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_fn = \"D:/cbr/VP2/VP2_SoilMapping/Shapes/train.shp\"\n",
    "train_ds = ogr.Open(train_fn)\n",
    "lyr = train_ds.GetLayer()\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_ds = driver.Create('', naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(naip_ds.GetProjection())\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    "data = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "print('min', data.min(), 'max', data.max(), 'mean', data.mean())\n",
    "\n",
    "ground_truth = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "classes = np.unique(ground_truth)[1:]\n",
    "print('class values', classes)\n",
    "\n",
    "segments_per_class = {}\n",
    "for klass in classes:\n",
    "    segments_of_class = segments[ground_truth == klass]\n",
    "    segments_per_class[klass] = set(segments_of_class)\n",
    "    print(\"Training segment for class\", klass, \":\", len(segments_of_class))\n",
    "\n",
    "intersection = set()\n",
    "accum = set()\n",
    "\n",
    "for class_segments in segments_per_class.values():\n",
    "    intersection |= accum.intersection(class_segments)\n",
    "    accum |= class_segments\n",
    "\n",
    "assert len(intersection) == 0, \"Segments represent multiple classes\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4161f7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ST1154~1\\AppData\\Local\\Temp/ipykernel_15588/3086628053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'classifier_prediction_model.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pygdal\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         )\n",
      "\u001b[1;32m~\\.conda\\envs\\pygdal\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pygdal\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pygdal\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    762\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "train_img = np.copy(segments)\n",
    "threshold = train_img.max() + 1\n",
    "\n",
    "for klass in classes:\n",
    "    class_label = threshold + klass\n",
    "    for segment_id in segments_per_class[klass]:\n",
    "        train_img[train_img == segment_id] = class_label\n",
    "\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold\n",
    "\n",
    "training_objects = []\n",
    "training_labels = []\n",
    "\n",
    "for klass in classes:\n",
    "    class_train_object = [v for i,v in enumerate(objects) if segment_ids[i] in segments_per_class[klass]]\n",
    "    training_labels += [klass] *len(class_train_object)\n",
    "    training_objects += class_train_object\n",
    "    print('Training objects for class', klass, ':', len(class_train_object))\n",
    "\n",
    "classifier = RandomForestClassifier(n_jobs=1)\n",
    "classifier.fit(training_objects, training_labels)\n",
    "\n",
    "filename = 'classifier_prediction_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "print('Fitting Random Forest Classifier')\n",
    "predicted = classifier.predict(objects)\n",
    "print('Predicting Classification')\n",
    "\n",
    "clf = np.copy(segments)\n",
    "for segment_id, klass in zip(segment_ids, predicted):\n",
    "    clf[clf == segment_id] = klass\n",
    "\n",
    "print('Prediction applied to numpy array')\n",
    "\n",
    "mask = np.sum(img, axis=2)\n",
    "mask[mask> 0] = 1.0\n",
    "mask[mask == 0] = -1.0\n",
    "\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0\n",
    "\n",
    "print('Saving classification to raster')\n",
    "def CreateGeoTiff(Name, Array, driver, GeoT, Projection, DataType):\n",
    "    DataSet = driver.Create(Name, naip_ds.RasterXSize, naip_ds.RasterYSize, 1, DataType)\n",
    "    DataSet.SetGeoTransform(GeoT)\n",
    "    DataSet.SetProjection(Projection)\n",
    "    DataSet.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "    DataSet.GetRasterBand(1).WriteArray(Array)\n",
    "    DataSet.FlushCache()\n",
    "    return Name\n",
    "\n",
    "CreateGeoTiff('D:/cbr/VP2/VP2_SoilMapping/Processed/classified_stack_mit_Punkten.tif', clf, gdal.GetDriverByName ( \"GTiff\" ), naip_ds.GetGeoTransform(), naip_ds.GetProjection(), gdal.GDT_Float32)\n",
    "print('Done')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b3869acfdba34c56e2bedf91b21357bab8a3024fdb722ea37327488350c28b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pygdal': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
